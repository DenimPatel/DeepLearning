{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardcoded.ipynb                mnist_train_images.npy\r\n",
      "MNIST-2-layer.-reference.ipynb mnist_train_labels.npy\r\n",
      "linux_bckup.ipynb              mnist_validation_images.npy\r\n",
      "mnist_test_images.npy          mnist_validation_labels.npy\r\n",
      "mnist_test_labels.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"mnist_train_images.npy\")\n",
    "y_train = np.load(\"mnist_train_labels.npy\")\n",
    "X_test = np.load(\"mnist_test_images.npy\")\n",
    "y_test = np.load(\"mnist_test_labels.npy\")\n",
    "X_validation = np.load(\"mnist_validation_images.npy\")\n",
    "y_validation = np.load(\"mnist_validation_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random([X_train.shape[1], y_train.shape[1]])\n",
    "b = np.random.random([1,y_train.shape[1]])\n",
    "model = {\n",
    "    \"w\": w,\n",
    "    \"b\": b\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "#     z -= np.max(z)\n",
    "    return (np.exp(z).T / np.sum(np.exp(z), axis=1))\n",
    "\n",
    "def forward_pass(x, model):\n",
    "    w= model[\"w\"]\n",
    "    b= model[\"b\"]\n",
    "    z = (x@w+b)\n",
    "    a = softmax(z).T\n",
    "#     y = np.argmax(a, axis=1)\n",
    "    return a\n",
    "\n",
    "def calculate_CE_loss(a, one_hot_y):\n",
    "    cost = (-1 / a.shape[0]) * np.sum(one_hot_y * np.log(a))\n",
    "    return cost\n",
    "\n",
    "def calculate_regularization(w,alpha):\n",
    "    REGULARIZATION = 0.5 * alpha * (w.T@w) \n",
    "    return REGULARIZATION\n",
    "def backprop(prediction, x, y, model, alpha=0.01, lr=0.00001):\n",
    "    w= model[\"w\"]\n",
    "    b= model[\"b\"]\n",
    "    grad_w = (-1/(x.shape[0]))*(x.T@(y-prediction)) + alpha * w\n",
    "    w = w - lr*grad_w\n",
    "    grad_b = -1*np.mean(y-prediction, axis = 0)\n",
    "    b = b - lr*grad_b\n",
    "    model[\"w\"] = w\n",
    "    model[\"b\"] = b\n",
    "    return model\n",
    "def evaluate(x = X_validation, y = y_validation, model=model, alpha=0.1):\n",
    "    prediction = forward_pass(x, model)\n",
    "    CE_loss = calculate_CE_loss(prediction, y)\n",
    "    w= model[\"w\"]\n",
    "    reg_loss = calculate_regularization(w,alpha)\n",
    "    return CE_loss+reg_loss\n",
    "def accuracy(y, y_true):\n",
    "    return (sum(y == y_true)/len(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - GRID SEARCH\n",
    "lrs = [3.3e-2]\n",
    "alphas = [0.001]\n",
    "batch_sizes = [50]\n",
    "epochs = [120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    activated = np.maximum(0, x) #just for clarification\n",
    "    return activated\n",
    "def reluDerivative(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "batch_size = 100\n",
    "data_x, data_y = X_train[(i)*batch_size:(i)*batch_size+batch_size,], y_train[(i)*batch_size:(i)*batch_size+batch_size,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z -= np.max(z)\n",
    "    return (np.exp(z).T / np.sum(np.exp(z), axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_neurons_1 = 75\n",
    "w1 = np.random.random([data_x.shape[1], many_neurons_1])/10\n",
    "b1 = np.random.random([1,many_neurons_1])/10\n",
    "\n",
    "many_neurons_2 = 50\n",
    "w2 = np.random.random([many_neurons_1, many_neurons_2])/10\n",
    "b2 = np.random.random([1,many_neurons_2])/10\n",
    "\n",
    "# many_neurons_2 = 50\n",
    "w3 = np.random.random([many_neurons_2, data_y.shape[1]])/10\n",
    "b3 = np.random.random([1,data_y.shape[1]])/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 hidden layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_neurons_1 = 75\n",
    "w1 = np.random.random([data_x.shape[1], many_neurons_1])/10\n",
    "b1 = np.random.random([1,many_neurons_1])/10\n",
    "\n",
    "many_neurons_2 = 50\n",
    "w2 = np.random.random([many_neurons_1, many_neurons_2])/10\n",
    "b2 = np.random.random([1,many_neurons_2])/10\n",
    "\n",
    "# many_neurons_2 = 50\n",
    "w3 = np.random.random([many_neurons_2, data_y.shape[1]])/10\n",
    "b3 = np.random.random([1,data_y.shape[1]])/10\n",
    "def val_accuracy(X_test,y_test,w1,w2,w3,b1,b2,b3):\n",
    "    z1 = np.dot(X_test,w1)+b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1,w2)+b2\n",
    "    a2 = relu(z2)\n",
    "    z3 = np.dot(a2,w3)+b3\n",
    "    a3 = softmax(z3).T\n",
    "    output = np.argmax(a3, axis=1)\n",
    "    actual_y = np.argmax(y_test, axis=1)\n",
    "    validation_accuracy = accuracy(output,actual_y)\n",
    "    print(validation_accuracy)\n",
    "    result = [a2,a3]\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [3.3e-2]\n",
    "alphas = [0.001]\n",
    "batch_sizes = [100]\n",
    "epochs = [200]\n",
    "\n",
    "for lr in lrs:\n",
    "    for alpha in alphas:\n",
    "        for batch_size in batch_sizes:\n",
    "            for epoch in epochs:\n",
    "                batches = (int)(len(X_train)/batch_size)\n",
    "                for _ in range(epoch):\n",
    "                    for i in range(batches):\n",
    "                        data_x, data_y = X_train[(i)*batch_size:(i)*batch_size+batch_size,], y_train[(i)*batch_size:(i)*batch_size+batch_size,]\n",
    "                        z1 = np.dot(data_x,w1)+b1\n",
    "                        a1 = relu(z1)\n",
    "                        z2 = np.dot(a1,w2)+b2\n",
    "                        a2 = relu(z2)\n",
    "                        z3 = np.dot(a2,w3)+b3\n",
    "                        a3 = softmax(z3).T\n",
    "\n",
    "                        batch = len(data_x)\n",
    "                        g = (np.subtract(a3,data_y))\n",
    "                        db3 = np.mean(g, axis = 0) \n",
    "                        dw3 = (1/batch)* np.dot(a2.T,(np.subtract(a3,data_y)))\n",
    "                        dw3 += alpha * w3\n",
    "\n",
    "                        g = np.multiply(np.dot(g,w3.T),reluDerivative(z2))\n",
    "                        db2 = np.mean(g, axis = 0)\n",
    "                        dw2 = (1/batch)* np.dot(a1.T,g)\n",
    "                        dw2 += alpha * w2\n",
    "                        \n",
    "                        g = np.multiply(np.dot(g,w2.T),reluDerivative(z1))\n",
    "                        db1 = np.mean(g, axis = 0)\n",
    "                        dw1 = (1/batch)* np.dot(data_x.T,g)\n",
    "                        dw1 +=  alpha * w1\n",
    "                        \n",
    "                        lr = 1e-2\n",
    "                        w3 -= lr*dw3\n",
    "                        w2 -= lr*dw2\n",
    "                        w1 -= lr*dw1\n",
    "\n",
    "                        b3 -= lr*db3\n",
    "                        b2 -= lr*db2\n",
    "                        b1 -= lr*db1\n",
    "                v = val_accuracy(data_x,data_y,w1,w2,w3,b1,b2,b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data - check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = np.dot(X_validation,w1)+b1\n",
    "a1 = relu(z1)\n",
    "z2 = np.dot(a1,w2)+b2\n",
    "a2 = relu(z2)\n",
    "z3 = np.dot(a2,w3)+b3\n",
    "a3 = softmax(z3).T\n",
    "output = np.argmax(a3, axis=1)\n",
    "actual_y = np.argmax(y_validation, axis=1)\n",
    "validation_accuracy = accuracy(output,actual_y)\n",
    "print(validation_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data - check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = np.dot(X_test,w1)+b1\n",
    "a1 = relu(z1)\n",
    "z2 = np.dot(a1,w2)+b2\n",
    "a2 = relu(z2)\n",
    "z3 = np.dot(a2,w3)+b3\n",
    "a3 = softmax(z3).T\n",
    "output = np.argmax(a3, axis=1)\n",
    "actual_y = np.argmax(y_test, axis=1)\n",
    "validation_accuracy = accuracy(output,actual_y)\n",
    "print(validation_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer - How to do it??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
